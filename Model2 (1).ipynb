{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "489224ac-8a1a-449f-8704-e8daa70b0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.1030 - accuracy: 0.0828 - val_loss: 2.0396 - val_accuracy: 0.3761\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.9985 - accuracy: 0.4437 - val_loss: 1.9226 - val_accuracy: 0.4679\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.8572 - accuracy: 0.4552 - val_loss: 1.7480 - val_accuracy: 0.4679\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.6508 - accuracy: 0.4552 - val_loss: 1.5287 - val_accuracy: 0.4679\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4776 - accuracy: 0.4552 - val_loss: 1.4571 - val_accuracy: 0.4679\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4232 - accuracy: 0.4552 - val_loss: 1.4273 - val_accuracy: 0.4679\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3796 - accuracy: 0.4667 - val_loss: 1.3917 - val_accuracy: 0.4771\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3375 - accuracy: 0.4920 - val_loss: 1.3696 - val_accuracy: 0.4862\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3027 - accuracy: 0.5149 - val_loss: 1.3455 - val_accuracy: 0.5321\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2617 - accuracy: 0.5356 - val_loss: 1.3345 - val_accuracy: 0.5321\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2206 - accuracy: 0.5471 - val_loss: 1.3349 - val_accuracy: 0.5321\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1823 - accuracy: 0.5678 - val_loss: 1.3325 - val_accuracy: 0.5413\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1424 - accuracy: 0.5747 - val_loss: 1.3447 - val_accuracy: 0.5413\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1087 - accuracy: 0.5816 - val_loss: 1.3566 - val_accuracy: 0.4954\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0779 - accuracy: 0.5931 - val_loss: 1.3846 - val_accuracy: 0.5138\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.6138 - val_loss: 1.4068 - val_accuracy: 0.5229\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0130 - accuracy: 0.6184 - val_loss: 1.4346 - val_accuracy: 0.4954\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9813 - accuracy: 0.6345 - val_loss: 1.4750 - val_accuracy: 0.5229\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.6345 - val_loss: 1.4947 - val_accuracy: 0.4954\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.6598 - val_loss: 1.5438 - val_accuracy: 0.5046\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9117 - accuracy: 0.6437 - val_loss: 1.5659 - val_accuracy: 0.4954\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8763 - accuracy: 0.6552 - val_loss: 1.6057 - val_accuracy: 0.4862\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8459 - accuracy: 0.6759 - val_loss: 1.6378 - val_accuracy: 0.4862\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8262 - accuracy: 0.6690 - val_loss: 1.6742 - val_accuracy: 0.5046\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8005 - accuracy: 0.6874 - val_loss: 1.7247 - val_accuracy: 0.4954\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.6920 - val_loss: 1.7597 - val_accuracy: 0.4862\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7619 - accuracy: 0.6897 - val_loss: 1.8012 - val_accuracy: 0.4862\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.6966 - val_loss: 1.8371 - val_accuracy: 0.4679\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7379 - accuracy: 0.6966 - val_loss: 1.8642 - val_accuracy: 0.4679\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7194 - accuracy: 0.6989 - val_loss: 1.9223 - val_accuracy: 0.4679\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7042 - accuracy: 0.7126 - val_loss: 1.9464 - val_accuracy: 0.4954\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.7241 - val_loss: 1.9896 - val_accuracy: 0.4862\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7218 - val_loss: 2.0094 - val_accuracy: 0.4587\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.7379 - val_loss: 2.0446 - val_accuracy: 0.4679\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.7287 - val_loss: 2.1011 - val_accuracy: 0.4587\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7494 - val_loss: 2.1008 - val_accuracy: 0.4312\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.7379 - val_loss: 2.1628 - val_accuracy: 0.4862\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.7333 - val_loss: 2.1541 - val_accuracy: 0.4679\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7402 - val_loss: 2.1905 - val_accuracy: 0.4679\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.7287 - val_loss: 2.2164 - val_accuracy: 0.4679\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7517 - val_loss: 2.2139 - val_accuracy: 0.4404\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7563 - val_loss: 2.2697 - val_accuracy: 0.4679\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7655 - val_loss: 2.2831 - val_accuracy: 0.4495\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7586 - val_loss: 2.3155 - val_accuracy: 0.4404\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7678 - val_loss: 2.3249 - val_accuracy: 0.4495\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7701 - val_loss: 2.3689 - val_accuracy: 0.4495\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7655 - val_loss: 2.3945 - val_accuracy: 0.4495\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7816 - val_loss: 2.3969 - val_accuracy: 0.4495\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7793 - val_loss: 2.4386 - val_accuracy: 0.4495\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7793 - val_loss: 2.4824 - val_accuracy: 0.4587\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7678 - val_loss: 2.4999 - val_accuracy: 0.4404\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7770 - val_loss: 2.4832 - val_accuracy: 0.4312\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7908 - val_loss: 2.5145 - val_accuracy: 0.4679\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.7862 - val_loss: 2.5705 - val_accuracy: 0.4587\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7747 - val_loss: 2.5441 - val_accuracy: 0.4587\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.8023 - val_loss: 2.6055 - val_accuracy: 0.4587\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7977 - val_loss: 2.6200 - val_accuracy: 0.4679\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.8092 - val_loss: 2.6367 - val_accuracy: 0.4404\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8138 - val_loss: 2.6642 - val_accuracy: 0.4495\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8207 - val_loss: 2.6988 - val_accuracy: 0.4679\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8253 - val_loss: 2.7139 - val_accuracy: 0.4587\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8115 - val_loss: 2.7584 - val_accuracy: 0.4495\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8069 - val_loss: 2.7624 - val_accuracy: 0.4404\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8253 - val_loss: 2.7909 - val_accuracy: 0.4679\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8161 - val_loss: 2.8014 - val_accuracy: 0.4679\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8230 - val_loss: 2.8506 - val_accuracy: 0.4495\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8184 - val_loss: 2.8582 - val_accuracy: 0.4495\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8115 - val_loss: 2.8729 - val_accuracy: 0.4587\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8207 - val_loss: 2.9340 - val_accuracy: 0.4495\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8184 - val_loss: 2.9095 - val_accuracy: 0.4312\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8276 - val_loss: 2.9306 - val_accuracy: 0.4404\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8253 - val_loss: 2.9652 - val_accuracy: 0.4495\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8023 - val_loss: 3.0322 - val_accuracy: 0.4404\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8368 - val_loss: 2.9757 - val_accuracy: 0.4495\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8391 - val_loss: 3.0156 - val_accuracy: 0.4312\n",
      "5/5 [==============================] - 0s 809us/step - loss: 2.6734 - accuracy: 0.4485\n",
      "Test accuracy: 0.4485294222831726\n",
      "3/3 [==============================] - 0s 780us/step\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yondawg/miniconda3/envs/NeuralNetworks/lib/python3.11/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/f261d78d1fb64e76bb18bb6bb3ddeff2-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/f261d78d1fb64e76bb18bb6bb3ddeff2-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 351 COLUMNS\n",
      "At line 2664 RHS\n",
      "At line 3011 BOUNDS\n",
      "At line 3420 ENDATA\n",
      "Problem MODEL has 346 rows, 408 columns and 1088 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 26.6962 - 0.00 seconds\n",
      "Cgl0004I processed model has 344 rows, 406 columns (406 integer (406 of which binary)) and 1216 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of -26.6962\n",
      "Cbc0038I Before mini branch and bound, 406 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.02 seconds)\n",
      "Cbc0038I After 0.02 seconds - Feasibility pump exiting with objective of -26.6962 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of -26.696203 found by feasibility pump after 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0001I Search completed - best objective -26.69620252866282, took 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -26.6962 to -26.6962\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                26.69620253\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.02\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.03\n",
      "\n",
      "   Predicted_POSTSEASON\n",
      "0              Champion\n",
      "1                  none\n",
      "2         Sweet Sixteen\n",
      "3           Round of 32\n",
      "4         Sweet Sixteen\n",
      "..                  ...\n",
      "63                 none\n",
      "64                 none\n",
      "65                 none\n",
      "66                 none\n",
      "67                 none\n",
      "\n",
      "[68 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "historical_data = pd.read_csv('/Users/yondawg/Documents/HistoricalData(2013-2023).csv')\n",
    "upcoming_season_data = pd.read_csv('/Users/yondawg/Documents/NewData(2024).csv')\n",
    "\n",
    "all_teams = pd.concat([historical_data['Team'], upcoming_season_data['Team']]).unique()\n",
    "team_to_index = {team: i + 1 for i, team in enumerate(all_teams)}\n",
    "team_to_index['unknown'] = 0\n",
    "\n",
    "historical_data['Team_idx'] = historical_data['Team'].map(team_to_index)\n",
    "upcoming_season_data['Team_idx'] = upcoming_season_data['Team'].apply(lambda x: team_to_index.get(x, 0))\n",
    "\n",
    "historical_features = pd.get_dummies(historical_data.drop(['POSTSEASON', 'Team'], axis=1), columns=['CONF'])\n",
    "scaler = MinMaxScaler()\n",
    "historical_features_scaled = scaler.fit_transform(historical_features)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "historical_target_encoded = encoder.fit_transform(historical_target)\n",
    "historical_target_one_hot = to_categorical(historical_target_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test, team_train, team_test = train_test_split(\n",
    "    historical_features_scaled, historical_target_one_hot, historical_data['Team_idx'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "team_input = Input(shape=(1,), dtype='int64', name='team_input')\n",
    "x = Embedding(input_dim=len(team_to_index) + 1, output_dim=10, input_length=1)(team_input)\n",
    "x = Flatten()(x)\n",
    "features_input = Input(shape=(X_train.shape[1],), name='features_input')\n",
    "x = Concatenate()([x, features_input])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "model = Model(inputs=[team_input, features_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([team_train, X_train], y_train, epochs=75, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate([team_test, X_test], y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Prepare upcoming season data for prediction\n",
    "upcoming_season_features = pd.get_dummies(upcoming_season_data.drop(['Team', 'Team_idx'], axis=1), columns=['CONF'])\n",
    "upcoming_season_features = upcoming_season_features.reindex(columns=historical_features.columns, fill_value=0)\n",
    "upcoming_season_features_scaled = scaler.transform(upcoming_season_features)\n",
    "#team_upcoming = upcoming_season_data['Team_idx']\n",
    "predictions = model.predict([team_upcoming, upcoming_season_features_scaled])\n",
    "\n",
    "# Define indices for readability in constraints (assuming model output order)\n",
    "CHAMPION, RUNNER_UP, FINAL_FOUR, ELITE_EIGHT, SWEET_SIXTEEN, ROUND_OF_32 = 0, 1, 2, 3, 4, 5\n",
    "\n",
    "num_teams = len(predictions)\n",
    "prob = pulp.LpProblem(\"Tournament_Place_Prediction\", pulp.LpMaximize)\n",
    "\n",
    "#creating binary variables for each category\n",
    "champions = pulp.LpVariable.dicts(\"Champion\", range(num_teams), cat=pulp.LpBinary)\n",
    "runners_up = pulp.LpVariable.dicts(\"Runner_Up\", range(num_teams), cat=pulp.LpBinary)\n",
    "final_four = pulp.LpVariable.dicts(\"Final_Four\", range(num_teams), cat=pulp.LpBinary)\n",
    "elite_eight = pulp.LpVariable.dicts(\"Elite_Eight\", range(num_teams), cat=pulp.LpBinary)\n",
    "sweet_sixteen = pulp.LpVariable.dicts(\"Sweet_Sixteen\", range(num_teams), cat=pulp.LpBinary)\n",
    "round_of_32 = pulp.LpVariable.dicts(\"Round_of_32\", range(num_teams), cat=pulp.LpBinary)\n",
    "\n",
    "#objective function\n",
    "prob += pulp.lpSum([\n",
    "    champions[i] * predictions[i, CHAMPION] +\n",
    "    runners_up[i] * predictions[i, RUNNER_UP] +\n",
    "    final_four[i] * predictions[i, FINAL_FOUR] +\n",
    "    elite_eight[i] * predictions[i, ELITE_EIGHT] +\n",
    "    sweet_sixteen[i] * predictions[i, SWEET_SIXTEEN] +\n",
    "    round_of_32[i] * predictions[i, ROUND_OF_32]\n",
    "    for i in range(num_teams)])\n",
    "\n",
    "# Constraints\n",
    "#one champion and runner-up\n",
    "prob += pulp.lpSum(champions) == 1\n",
    "prob += pulp.lpSum(runners_up) == 1\n",
    "\n",
    "#4 Final Four teams (including champion and runner-up)\n",
    "prob += pulp.lpSum(final_four) == 4\n",
    "for i in range(num_teams):\n",
    "    prob += final_four[i] >= champions[i]\n",
    "    prob += final_four[i] >= runners_up[i]\n",
    "\n",
    "#8 Elite Eight teams (including Final Four)\n",
    "prob += pulp.lpSum(elite_eight) == 8\n",
    "for i in range(num_teams):\n",
    "    prob += elite_eight[i] >= final_four[i]\n",
    "\n",
    "#16 Sweet Sixteen teams (including Elite Eight)\n",
    "prob += pulp.lpSum(sweet_sixteen) == 16\n",
    "for i in range(num_teams):\n",
    "    prob += sweet_sixteen[i] >= elite_eight[i]\n",
    "\n",
    "#32 Round of 32 teams (including Sweet Sixteen)\n",
    "prob += pulp.lpSum(round_of_32) == 32\n",
    "for i in range(num_teams):\n",
    "    prob += round_of_32[i] >= sweet_sixteen[i]\n",
    "\n",
    "# Solve the ILP problem\n",
    "prob.solve()\n",
    "\n",
    "# Extract results and map back to teams\n",
    "postseason_roles = [\"none\"] * num_teams\n",
    "for i in range(num_teams):\n",
    "    if pulp.value(champions[i]):\n",
    "        postseason_roles[i] = \"Champion\"\n",
    "    elif pulp.value(runners_up[i]):\n",
    "        postseason_roles[i] = \"Runner Up\"\n",
    "    elif pulp.value(final_four[i]):\n",
    "        postseason_roles[i] = \"Final Four\"\n",
    "    elif pulp.value(elite_eight[i]):\n",
    "        postseason_roles[i] = \"Elite Eight\"\n",
    "    elif pulp.value(sweet_sixteen[i]):\n",
    "        postseason_roles[i] = \"Sweet Sixteen\"\n",
    "    elif pulp.value(round_of_32[i]):\n",
    "        postseason_roles[i] = \"Round of 32\"\n",
    "\n",
    "upcoming_season_data['Predicted_POSTSEASON'] = postseason_roles\n",
    "print(upcoming_season_data[['Predicted_POSTSEASON']])\n",
    "\n",
    "# Save the predictions\n",
    "upcoming_season_data.to_csv('/Users/yondawg/Documents/UpcomingSeasonPredictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9ac05-1943-49a6-800b-c5f830caaba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
