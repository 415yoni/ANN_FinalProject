{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "acaf2978-4206-47b5-b168-13cf0ee8de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.9987 - accuracy: 0.3862 - val_loss: 1.9060 - val_accuracy: 0.4679\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.8172 - accuracy: 0.4552 - val_loss: 1.6947 - val_accuracy: 0.4679\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.6147 - accuracy: 0.4552 - val_loss: 1.5337 - val_accuracy: 0.4679\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5032 - accuracy: 0.4644 - val_loss: 1.4822 - val_accuracy: 0.4862\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4485 - accuracy: 0.4391 - val_loss: 1.4423 - val_accuracy: 0.5046\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.4506 - val_loss: 1.4188 - val_accuracy: 0.5229\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.4966 - val_loss: 1.3970 - val_accuracy: 0.5046\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3597 - accuracy: 0.5057 - val_loss: 1.3722 - val_accuracy: 0.5138\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3371 - accuracy: 0.5057 - val_loss: 1.3659 - val_accuracy: 0.5046\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3164 - accuracy: 0.5149 - val_loss: 1.3472 - val_accuracy: 0.5138\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2983 - accuracy: 0.5287 - val_loss: 1.3506 - val_accuracy: 0.5413\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2850 - accuracy: 0.4897 - val_loss: 1.3327 - val_accuracy: 0.5046\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2629 - accuracy: 0.5333 - val_loss: 1.3249 - val_accuracy: 0.5138\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2471 - accuracy: 0.5195 - val_loss: 1.3199 - val_accuracy: 0.5229\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2292 - accuracy: 0.5356 - val_loss: 1.3179 - val_accuracy: 0.5046\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2156 - accuracy: 0.5402 - val_loss: 1.3115 - val_accuracy: 0.4954\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2037 - accuracy: 0.5264 - val_loss: 1.3184 - val_accuracy: 0.4954\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1949 - accuracy: 0.5195 - val_loss: 1.3080 - val_accuracy: 0.5138\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1771 - accuracy: 0.5287 - val_loss: 1.3220 - val_accuracy: 0.5046\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1753 - accuracy: 0.5379 - val_loss: 1.3124 - val_accuracy: 0.4862\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1590 - accuracy: 0.5517 - val_loss: 1.3215 - val_accuracy: 0.4679\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1500 - accuracy: 0.5425 - val_loss: 1.3176 - val_accuracy: 0.4679\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.5678 - val_loss: 1.3339 - val_accuracy: 0.4404\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1384 - accuracy: 0.5471 - val_loss: 1.3274 - val_accuracy: 0.4771\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1278 - accuracy: 0.5586 - val_loss: 1.3329 - val_accuracy: 0.4954\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1217 - accuracy: 0.5678 - val_loss: 1.3325 - val_accuracy: 0.4679\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1153 - accuracy: 0.5540 - val_loss: 1.3392 - val_accuracy: 0.4862\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1056 - accuracy: 0.5586 - val_loss: 1.3431 - val_accuracy: 0.4771\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.5632 - val_loss: 1.3553 - val_accuracy: 0.4587\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1018 - accuracy: 0.5885 - val_loss: 1.3469 - val_accuracy: 0.4679\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0898 - accuracy: 0.5678 - val_loss: 1.3539 - val_accuracy: 0.4862\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0809 - accuracy: 0.5563 - val_loss: 1.3567 - val_accuracy: 0.4587\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0817 - accuracy: 0.5839 - val_loss: 1.3621 - val_accuracy: 0.4587\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0737 - accuracy: 0.5724 - val_loss: 1.3712 - val_accuracy: 0.4771\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0736 - accuracy: 0.5701 - val_loss: 1.3696 - val_accuracy: 0.4587\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0671 - accuracy: 0.5540 - val_loss: 1.3692 - val_accuracy: 0.4679\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.5816 - val_loss: 1.3940 - val_accuracy: 0.4587\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5816 - val_loss: 1.3795 - val_accuracy: 0.4679\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0399 - accuracy: 0.6046 - val_loss: 1.3942 - val_accuracy: 0.4862\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0426 - accuracy: 0.5954 - val_loss: 1.3884 - val_accuracy: 0.4587\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.5954 - val_loss: 1.4048 - val_accuracy: 0.4587\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5816 - val_loss: 1.4102 - val_accuracy: 0.4587\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0248 - accuracy: 0.5839 - val_loss: 1.4013 - val_accuracy: 0.4771\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0173 - accuracy: 0.6023 - val_loss: 1.4108 - val_accuracy: 0.4404\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0081 - accuracy: 0.5885 - val_loss: 1.4088 - val_accuracy: 0.4679\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.6023 - val_loss: 1.4110 - val_accuracy: 0.4587\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0065 - accuracy: 0.5977 - val_loss: 1.4239 - val_accuracy: 0.4587\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9938 - accuracy: 0.6138 - val_loss: 1.4301 - val_accuracy: 0.4495\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.6046 - val_loss: 1.4210 - val_accuracy: 0.4587\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9832 - accuracy: 0.6161 - val_loss: 1.4326 - val_accuracy: 0.4495\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9804 - accuracy: 0.6069 - val_loss: 1.4369 - val_accuracy: 0.4679\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9772 - accuracy: 0.6115 - val_loss: 1.4540 - val_accuracy: 0.4495\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9700 - accuracy: 0.6184 - val_loss: 1.4389 - val_accuracy: 0.4587\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9692 - accuracy: 0.6230 - val_loss: 1.4529 - val_accuracy: 0.4587\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9572 - accuracy: 0.6161 - val_loss: 1.4503 - val_accuracy: 0.4679\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.6138 - val_loss: 1.4613 - val_accuracy: 0.4495\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.6345 - val_loss: 1.4730 - val_accuracy: 0.4404\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9498 - accuracy: 0.6276 - val_loss: 1.4705 - val_accuracy: 0.4587\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.6322 - val_loss: 1.4696 - val_accuracy: 0.4312\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9412 - accuracy: 0.6253 - val_loss: 1.4796 - val_accuracy: 0.4495\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6391 - val_loss: 1.4851 - val_accuracy: 0.4404\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6437 - val_loss: 1.4881 - val_accuracy: 0.4404\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9219 - accuracy: 0.6506 - val_loss: 1.4834 - val_accuracy: 0.4587\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.6345 - val_loss: 1.5010 - val_accuracy: 0.4587\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9143 - accuracy: 0.6552 - val_loss: 1.5058 - val_accuracy: 0.4312\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.6230 - val_loss: 1.5050 - val_accuracy: 0.4404\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9006 - accuracy: 0.6437 - val_loss: 1.5072 - val_accuracy: 0.4312\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8969 - accuracy: 0.6437 - val_loss: 1.5262 - val_accuracy: 0.4220\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8783 - accuracy: 0.6483 - val_loss: 1.5353 - val_accuracy: 0.4495\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.6575 - val_loss: 1.5362 - val_accuracy: 0.4312\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8840 - accuracy: 0.6460 - val_loss: 1.5394 - val_accuracy: 0.4312\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6391 - val_loss: 1.5451 - val_accuracy: 0.4037\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8825 - accuracy: 0.6460 - val_loss: 1.5522 - val_accuracy: 0.4312\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8705 - accuracy: 0.6506 - val_loss: 1.5577 - val_accuracy: 0.4679\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8551 - accuracy: 0.6460 - val_loss: 1.5746 - val_accuracy: 0.4220\n",
      "5/5 [==============================] - 0s 677us/step - loss: 1.6408 - accuracy: 0.4632\n",
      "Test accuracy: 0.4632352888584137\n",
      "3/3 [==============================] - 0s 818us/step\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yondawg/miniconda3/envs/NeuralNetworks/lib/python3.11/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/70a633211b734b868b9f1067b8338de3-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/70a633211b734b868b9f1067b8338de3-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 351 COLUMNS\n",
      "At line 2664 RHS\n",
      "At line 3011 BOUNDS\n",
      "At line 3420 ENDATA\n",
      "Problem MODEL has 346 rows, 408 columns and 1088 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 22.5839 - 0.00 seconds\n",
      "Cgl0004I processed model has 344 rows, 406 columns (406 integer (406 of which binary)) and 1216 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of -22.5839\n",
      "Cbc0038I Before mini branch and bound, 406 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of -22.5839 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of -22.583912 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective -22.5839116573336, took 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -22.5839 to -22.5839\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                22.58391166\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pulp\n",
    "\n",
    "#change the file path for both the datasets \n",
    "#i'll send an email of both that I updated \n",
    "historical_data = pd.read_csv('/Users/yondawg/Documents/HistoricalData(2013-2023).csv')\n",
    "historical_data = historical_data.drop(['Team'], axis=1)\n",
    "\n",
    "historical_features = pd.get_dummies(historical_data.drop('POSTSEASON', axis=1), columns=['CONF'])\n",
    "historical_target = historical_data['POSTSEASON']\n",
    "\n",
    "\n",
    "upcoming_season_data = pd.read_csv('/Users/yondawg/Documents/NewData(2024).csv')\n",
    "upcoming_season_data = upcoming_season_data.drop(['Team'], axis=1)\n",
    "upcoming_season_features = pd.get_dummies(upcoming_season_data, columns=['CONF'])\n",
    "\n",
    "#align the feature columns in the upcoming season data with the historical features\n",
    "upcoming_season_features = upcoming_season_features.reindex(columns=historical_features.columns, fill_value=0)\n",
    "\n",
    "#normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "historical_features_scaled = scaler.fit_transform(historical_features)\n",
    "upcoming_season_features_scaled = scaler.transform(upcoming_season_features)\n",
    "\n",
    "#historical_features_scaled\n",
    "#upcoming_season_features_scaled\n",
    "encoder = LabelEncoder()\n",
    "historical_target_encoded = encoder.fit_transform(historical_target)\n",
    "historical_target_one_hot = to_categorical(historical_target_encoded)\n",
    "\n",
    "#split up the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(historical_features_scaled, historical_target_one_hot, test_size=0.2, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(historical_features_scaled, historical_target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(8, activation='softmax')  #7 different outcomes for the output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=75, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(upcoming_season_features_scaled)\n",
    "\n",
    "#convert predictions to labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "\n",
    "CHAMPION, RUNNER_UP, FINAL_FOUR, ELITE_EIGHT, SWEET_SIXTEEN, ROUND_OF_32 = 0, 1, 2, 3, 4, 5\n",
    "\n",
    "num_teams = len(predictions)\n",
    "prob = pulp.LpProblem(\"Tournament_Place_Prediction\", pulp.LpMaximize)\n",
    "\n",
    "#creating binary variables for each category\n",
    "champions = pulp.LpVariable.dicts(\"Champion\", range(num_teams), cat=pulp.LpBinary)\n",
    "runners_up = pulp.LpVariable.dicts(\"Runner_Up\", range(num_teams), cat=pulp.LpBinary)\n",
    "final_four = pulp.LpVariable.dicts(\"Final_Four\", range(num_teams), cat=pulp.LpBinary)\n",
    "elite_eight = pulp.LpVariable.dicts(\"Elite_Eight\", range(num_teams), cat=pulp.LpBinary)\n",
    "sweet_sixteen = pulp.LpVariable.dicts(\"Sweet_Sixteen\", range(num_teams), cat=pulp.LpBinary)\n",
    "round_of_32 = pulp.LpVariable.dicts(\"Round_of_32\", range(num_teams), cat=pulp.LpBinary)\n",
    "\n",
    "# Objective function\n",
    "prob += pulp.lpSum([\n",
    "    champions[i] * predictions[i, CHAMPION] +\n",
    "    runners_up[i] * predictions[i, RUNNER_UP] +\n",
    "    final_four[i] * predictions[i, FINAL_FOUR] +\n",
    "    elite_eight[i] * predictions[i, ELITE_EIGHT] +\n",
    "    sweet_sixteen[i] * predictions[i, SWEET_SIXTEEN] +\n",
    "    round_of_32[i] * predictions[i, ROUND_OF_32]\n",
    "    for i in range(num_teams)])\n",
    "\n",
    "# Constraints\n",
    "#one champion and runner-up\n",
    "prob += pulp.lpSum(champions) == 1\n",
    "prob += pulp.lpSum(runners_up) == 1\n",
    "\n",
    "#4 Final Four teams (including champion and runner-up)\n",
    "prob += pulp.lpSum(final_four) == 4\n",
    "for i in range(num_teams):\n",
    "    prob += final_four[i] >= champions[i]\n",
    "    prob += final_four[i] >= runners_up[i]\n",
    "\n",
    "#8 Elite Eight teams (including Final Four)\n",
    "prob += pulp.lpSum(elite_eight) == 8\n",
    "for i in range(num_teams):\n",
    "    prob += elite_eight[i] >= final_four[i]\n",
    "\n",
    "#16 Sweet Sixteen teams (including Elite Eight)\n",
    "prob += pulp.lpSum(sweet_sixteen) == 16\n",
    "for i in range(num_teams):\n",
    "    prob += sweet_sixteen[i] >= elite_eight[i]\n",
    "\n",
    "#32 Round of 32 teams (including Sweet Sixteen)\n",
    "prob += pulp.lpSum(round_of_32) == 32\n",
    "for i in range(num_teams):\n",
    "    prob += round_of_32[i] >= sweet_sixteen[i]\n",
    "\n",
    "#solve the ILP problem\n",
    "prob.solve()\n",
    "\n",
    "#map results back to teams\n",
    "postseason_roles = [\"None\"] * num_teams\n",
    "for i in range(num_teams):\n",
    "    if pulp.value(champions[i]):\n",
    "        postseason_roles[i] = \"Champion\"\n",
    "    elif pulp.value(runners_up[i]):\n",
    "        postseason_roles[i] = \"Runner Up\"\n",
    "    elif pulp.value(final_four[i]):\n",
    "        postseason_roles[i] = \"Final Four\"\n",
    "    elif pulp.value(elite_eight[i]):\n",
    "        postseason_roles[i] = \"Elite Eight\"\n",
    "    elif pulp.value(sweet_sixteen[i]):\n",
    "        postseason_roles[i] = \"Sweet Sixteen\"\n",
    "    elif pulp.value(round_of_32[i]):\n",
    "        postseason_roles[i] = \"Round of 32\"\n",
    "\n",
    "upcoming_season_data['Predicted_POSTSEASON'] = postseason_roles\n",
    "\n",
    "# Save the predictions\n",
    "upcoming_season_data.to_csv('/Users/yondawg/Documents/UpcomingSeasonPredictions(no-names).csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a8597-84f4-40d0-aa2d-bed06deb433d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
