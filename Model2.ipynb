{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489224ac-8a1a-449f-8704-e8daa70b0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.9730 - accuracy: 0.2414 - val_loss: 1.8454 - val_accuracy: 0.2936\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.7402 - accuracy: 0.3954 - val_loss: 1.6687 - val_accuracy: 0.4404\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5898 - accuracy: 0.4552 - val_loss: 1.5832 - val_accuracy: 0.4679\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5173 - accuracy: 0.4552 - val_loss: 1.5373 - val_accuracy: 0.4679\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4679 - accuracy: 0.4552 - val_loss: 1.5234 - val_accuracy: 0.4679\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4313 - accuracy: 0.4552 - val_loss: 1.4985 - val_accuracy: 0.4679\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.4529 - val_loss: 1.4740 - val_accuracy: 0.4679\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3542 - accuracy: 0.4690 - val_loss: 1.4639 - val_accuracy: 0.5229\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3066 - accuracy: 0.5103 - val_loss: 1.4439 - val_accuracy: 0.5413\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2553 - accuracy: 0.5241 - val_loss: 1.4503 - val_accuracy: 0.5138\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2089 - accuracy: 0.5264 - val_loss: 1.4582 - val_accuracy: 0.5138\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1590 - accuracy: 0.5402 - val_loss: 1.4823 - val_accuracy: 0.4771\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.5747 - val_loss: 1.5245 - val_accuracy: 0.4771\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0875 - accuracy: 0.5724 - val_loss: 1.5645 - val_accuracy: 0.4312\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.5908 - val_loss: 1.5910 - val_accuracy: 0.4312\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.6023 - val_loss: 1.6074 - val_accuracy: 0.4404\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0127 - accuracy: 0.6230 - val_loss: 1.6413 - val_accuracy: 0.4495\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9989 - accuracy: 0.6161 - val_loss: 1.6758 - val_accuracy: 0.4312\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9687 - accuracy: 0.6184 - val_loss: 1.6763 - val_accuracy: 0.4679\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.6299 - val_loss: 1.7091 - val_accuracy: 0.4404\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9238 - accuracy: 0.6621 - val_loss: 1.7104 - val_accuracy: 0.4312\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.6414 - val_loss: 1.7654 - val_accuracy: 0.4312\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8771 - accuracy: 0.6690 - val_loss: 1.7828 - val_accuracy: 0.4220\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.6644 - val_loss: 1.8193 - val_accuracy: 0.4312\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8503 - accuracy: 0.6713 - val_loss: 1.8653 - val_accuracy: 0.4404\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8430 - accuracy: 0.6690 - val_loss: 1.8844 - val_accuracy: 0.4495\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8179 - accuracy: 0.6644 - val_loss: 1.8956 - val_accuracy: 0.4220\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8102 - accuracy: 0.6690 - val_loss: 1.9140 - val_accuracy: 0.4495\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8067 - accuracy: 0.6759 - val_loss: 1.9680 - val_accuracy: 0.4495\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.6989 - val_loss: 1.9678 - val_accuracy: 0.4495\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.6851 - val_loss: 2.0169 - val_accuracy: 0.4220\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7560 - accuracy: 0.6920 - val_loss: 2.0609 - val_accuracy: 0.4495\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.6989 - val_loss: 2.0906 - val_accuracy: 0.4495\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.6897 - val_loss: 2.1040 - val_accuracy: 0.4404\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7308 - accuracy: 0.7264 - val_loss: 2.1659 - val_accuracy: 0.4771\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.6989 - val_loss: 2.1676 - val_accuracy: 0.4404\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.7034 - val_loss: 2.2040 - val_accuracy: 0.4771\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7149 - val_loss: 2.2048 - val_accuracy: 0.4495\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.7195 - val_loss: 2.2791 - val_accuracy: 0.4587\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.7080 - val_loss: 2.2793 - val_accuracy: 0.4587\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.7218 - val_loss: 2.2756 - val_accuracy: 0.4495\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.7195 - val_loss: 2.3587 - val_accuracy: 0.4771\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.7287 - val_loss: 2.3694 - val_accuracy: 0.4679\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.7218 - val_loss: 2.4123 - val_accuracy: 0.4771\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.7402 - val_loss: 2.4209 - val_accuracy: 0.4587\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.7402 - val_loss: 2.4385 - val_accuracy: 0.4587\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.7402 - val_loss: 2.4611 - val_accuracy: 0.4312\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.7264 - val_loss: 2.4937 - val_accuracy: 0.4771\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.7494 - val_loss: 2.5062 - val_accuracy: 0.4771\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.7402 - val_loss: 2.5645 - val_accuracy: 0.4404\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.7586 - val_loss: 2.5922 - val_accuracy: 0.4312\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7517 - val_loss: 2.5823 - val_accuracy: 0.4404\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7471 - val_loss: 2.6733 - val_accuracy: 0.4495\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.7425 - val_loss: 2.6751 - val_accuracy: 0.4587\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7609 - val_loss: 2.6447 - val_accuracy: 0.4587\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7632 - val_loss: 2.7129 - val_accuracy: 0.4495\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7655 - val_loss: 2.7509 - val_accuracy: 0.4587\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7494 - val_loss: 2.7605 - val_accuracy: 0.4679\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7425 - val_loss: 2.7404 - val_accuracy: 0.4220\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7563 - val_loss: 2.8547 - val_accuracy: 0.4771\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7793 - val_loss: 2.8277 - val_accuracy: 0.4587\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7816 - val_loss: 2.9192 - val_accuracy: 0.4587\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7770 - val_loss: 2.9194 - val_accuracy: 0.4495\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7816 - val_loss: 2.9663 - val_accuracy: 0.4862\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7655 - val_loss: 2.9956 - val_accuracy: 0.4587\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7540 - val_loss: 3.0130 - val_accuracy: 0.4587\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7793 - val_loss: 3.0237 - val_accuracy: 0.4771\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7931 - val_loss: 3.0421 - val_accuracy: 0.4495\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8000 - val_loss: 3.1166 - val_accuracy: 0.4679\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8046 - val_loss: 3.1142 - val_accuracy: 0.4312\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7954 - val_loss: 3.1580 - val_accuracy: 0.4495\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7701 - val_loss: 3.1535 - val_accuracy: 0.4220\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7908 - val_loss: 3.2251 - val_accuracy: 0.4771\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7908 - val_loss: 3.1701 - val_accuracy: 0.4495\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7954 - val_loss: 3.2148 - val_accuracy: 0.4404\n",
      "5/5 [==============================] - 0s 868us/step - loss: 3.2225 - accuracy: 0.4853\n",
      "Test accuracy: 0.4852941036224365\n",
      "3/3 [==============================] - 0s 927us/step\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yondawg/miniconda3/envs/NeuralNetworks/lib/python3.11/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/0704c2bb7cfc424d82d9a49b8281e6ea-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/r9/3d5_w3n54sb1n665sh5c25r00000gn/T/0704c2bb7cfc424d82d9a49b8281e6ea-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 351 COLUMNS\n",
      "At line 2664 RHS\n",
      "At line 3011 BOUNDS\n",
      "At line 3420 ENDATA\n",
      "Problem MODEL has 346 rows, 408 columns and 1088 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 24.0291 - 0.00 seconds\n",
      "Cgl0004I processed model has 344 rows, 406 columns (406 integer (406 of which binary)) and 1216 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of -24.0291\n",
      "Cbc0038I Before mini branch and bound, 406 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.02 seconds)\n",
      "Cbc0038I After 0.02 seconds - Feasibility pump exiting with objective of -24.0291 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of -24.029121 found by feasibility pump after 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0001I Search completed - best objective -24.02912086248427, took 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -24.0291 to -24.0291\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                24.02912086\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.01\n",
      "Time (Wallclock seconds):       0.02\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.03\n",
      "\n",
      "   Predicted_POSTSEASON\n",
      "0              Champion\n",
      "1            Final Four\n",
      "2           Elite Eight\n",
      "3            Final Four\n",
      "4         Sweet Sixteen\n",
      "..                  ...\n",
      "63                 none\n",
      "64                 none\n",
      "65                 none\n",
      "66                 none\n",
      "67                 none\n",
      "\n",
      "[68 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load datasets and preprocess as before\n",
    "historical_data = pd.read_csv('/Users/yondawg/Documents/HistoricalData(2013-2023).csv')\n",
    "upcoming_season_data = pd.read_csv('/Users/yondawg/Documents/NewData(2024).csv')\n",
    "\n",
    "all_teams = pd.concat([historical_data['Team'], upcoming_season_data['Team']]).unique()\n",
    "team_to_index = {team: i + 1 for i, team in enumerate(all_teams)}\n",
    "team_to_index['unknown'] = 0\n",
    "\n",
    "historical_data['Team_idx'] = historical_data['Team'].map(team_to_index)\n",
    "upcoming_season_data['Team_idx'] = upcoming_season_data['Team'].apply(lambda x: team_to_index.get(x, 0))\n",
    "\n",
    "historical_features = pd.get_dummies(historical_data.drop(['POSTSEASON', 'Team'], axis=1), columns=['CONF'])\n",
    "scaler = MinMaxScaler()\n",
    "historical_features_scaled = scaler.fit_transform(historical_features)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "historical_target_encoded = encoder.fit_transform(historical_target)\n",
    "historical_target_one_hot = to_categorical(historical_target_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test, team_train, team_test = train_test_split(\n",
    "    historical_features_scaled, historical_target_one_hot, historical_data['Team_idx'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define your neural network structure and compile it as before\n",
    "team_input = Input(shape=(1,), dtype='int64', name='team_input')\n",
    "x = Embedding(input_dim=len(team_to_index) + 1, output_dim=10, input_length=1)(team_input)\n",
    "x = Flatten()(x)\n",
    "features_input = Input(shape=(X_train.shape[1],), name='features_input')\n",
    "x = Concatenate()([x, features_input])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "model = Model(inputs=[team_input, features_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([team_train, X_train], y_train, epochs=75, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Model evaluation\n",
    "loss, accuracy = model.evaluate([team_test, X_test], y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Prepare upcoming season data for prediction\n",
    "upcoming_season_features = pd.get_dummies(upcoming_season_data.drop(['Team', 'Team_idx'], axis=1), columns=['CONF'])\n",
    "upcoming_season_features = upcoming_season_features.reindex(columns=historical_features.columns, fill_value=0)\n",
    "upcoming_season_features_scaled = scaler.transform(upcoming_season_features)\n",
    "team_upcoming = upcoming_season_data['Team_idx']\n",
    "predictions = model.predict([team_upcoming, upcoming_season_features_scaled])\n",
    "\n",
    "# Define indices for readability in constraints (assuming model output order)\n",
    "CHAMPION, RUNNER_UP, FINAL_FOUR, ELITE_EIGHT, SWEET_SIXTEEN, ROUND_OF_32 = 0, 1, 2, 3, 4, 5\n",
    "\n",
    "num_teams = len(predictions)\n",
    "prob = pulp.LpProblem(\"Tournament_Place_Prediction\", pulp.LpMaximize)\n",
    "\n",
    "# Creating binary variables for each category\n",
    "champions = pulp.LpVariable.dicts(\"Champion\", range(num_teams), cat=pulp.LpBinary)\n",
    "runners_up = pulp.LpVariable.dicts(\"Runner_Up\", range(num_teams), cat=pulp.LpBinary)\n",
    "final_four = pulp.LpVariable.dicts(\"Final_Four\", range(num_teams), cat=pulp.LpBinary)\n",
    "elite_eight = pulp.LpVariable.dicts(\"Elite_Eight\", range(num_teams), cat=pulp.LpBinary)\n",
    "sweet_sixteen = pulp.LpVariable.dicts(\"Sweet_Sixteen\", range(num_teams), cat=pulp.LpBinary)\n",
    "round_of_32 = pulp.LpVariable.dicts(\"Round_of_32\", range(num_teams), cat=pulp.LpBinary)\n",
    "\n",
    "# Objective function\n",
    "prob += pulp.lpSum([\n",
    "    champions[i] * predictions[i, CHAMPION] +\n",
    "    runners_up[i] * predictions[i, RUNNER_UP] +\n",
    "    final_four[i] * predictions[i, FINAL_FOUR] +\n",
    "    elite_eight[i] * predictions[i, ELITE_EIGHT] +\n",
    "    sweet_sixteen[i] * predictions[i, SWEET_SIXTEEN] +\n",
    "    round_of_32[i] * predictions[i, ROUND_OF_32]\n",
    "    for i in range(num_teams)])\n",
    "\n",
    "# Constraints\n",
    "# Single champion and runner-up\n",
    "prob += pulp.lpSum(champions) == 1\n",
    "prob += pulp.lpSum(runners_up) == 1\n",
    "\n",
    "# Four Final Four teams (including champion and runner-up)\n",
    "prob += pulp.lpSum(final_four) == 4\n",
    "for i in range(num_teams):\n",
    "    prob += final_four[i] >= champions[i]\n",
    "    prob += final_four[i] >= runners_up[i]\n",
    "\n",
    "# Eight Elite Eight teams (including Final Four)\n",
    "prob += pulp.lpSum(elite_eight) == 8\n",
    "for i in range(num_teams):\n",
    "    prob += elite_eight[i] >= final_four[i]\n",
    "\n",
    "# Sixteen Sweet Sixteen teams (including Elite Eight)\n",
    "prob += pulp.lpSum(sweet_sixteen) == 16\n",
    "for i in range(num_teams):\n",
    "    prob += sweet_sixteen[i] >= elite_eight[i]\n",
    "\n",
    "# Thirty-two Round of 32 teams (including Sweet Sixteen)\n",
    "prob += pulp.lpSum(round_of_32) == 32\n",
    "for i in range(num_teams):\n",
    "    prob += round_of_32[i] >= sweet_sixteen[i]\n",
    "\n",
    "# Solve the ILP problem\n",
    "prob.solve()\n",
    "\n",
    "# Extract results and map back to teams\n",
    "postseason_roles = [\"none\"] * num_teams\n",
    "for i in range(num_teams):\n",
    "    if pulp.value(champions[i]):\n",
    "        postseason_roles[i] = \"Champion\"\n",
    "    elif pulp.value(runners_up[i]):\n",
    "        postseason_roles[i] = \"Runner Up\"\n",
    "    elif pulp.value(final_four[i]):\n",
    "        postseason_roles[i] = \"Final Four\"\n",
    "    elif pulp.value(elite_eight[i]):\n",
    "        postseason_roles[i] = \"Elite Eight\"\n",
    "    elif pulp.value(sweet_sixteen[i]):\n",
    "        postseason_roles[i] = \"Sweet Sixteen\"\n",
    "    elif pulp.value(round_of_32[i]):\n",
    "        postseason_roles[i] = \"Round of 32\"\n",
    "\n",
    "upcoming_season_data['Predicted_POSTSEASON'] = postseason_roles\n",
    "print(upcoming_season_data[['Predicted_POSTSEASON']])\n",
    "\n",
    "# Save the predictions\n",
    "upcoming_season_data.to_csv('/Users/yondawg/Documents/UpcomingSeasonPredictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9ac05-1943-49a6-800b-c5f830caaba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
